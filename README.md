# AnchorTel â€“ Genâ€‘AI Telecom Chatbot

A fullâ€‘stack customerâ€‘support assistant that combines **retrievalâ€‘augmented generation (RAG)** with taskâ€‘oriented tools **and an automatic evaluation pipeline**. Built with **FastAPI**, **LangChain / LangGraph**, **OpenAI GPTâ€‘4o**, and packaged for **Docker â†’ Google Cloud Run**.
<p align="center">
  <img src="backend/images/anchortel_chatbot_arch_enhanced.png" width="720"/>
</p>
---

## ğŸ”‘ Key Features

| Theme                    | What it delivers                                                                                              |
| ------------------------ | ------------------------------------------------------------------------------------------------------------- |
| **RAGâ€‘grounded answers** | Vector store anchors every response in AnchorTel docs; sources optionally returned.                           |
| **Tool invocation**      | Secure APIs let the agent create accounts, reset passwords, and pull billing infoâ€”directly from chat.         |
| **Session memory**       | Token buffer (\~2â€¯000 tokens) enables multiâ€‘turn support without losing context.                              |
| **Automatic evaluation** | Oneâ€‘click Excel workflow: generate reference Q&A, upload edits, and receive five **LLMâ€‘based RAGAS metrics**. |
| **Observability & logs** | OpenTelemetry traces + SQLite log of unanswered queries for continuous improvement.                           |
| **Cloudâ€‘ready**          | Single Docker image or Cloud Run deployment; .envâ€‘driven secrets.                                             |

---

## ğŸ“ Project Structure

```text
anchortel/
â”œâ”€â”€ backend/
â”‚   â”œâ”€â”€ main.py          # FastAPI entry (chat + eval)
â”‚   â”œâ”€â”€ agent_logic.py   # LangChain agent + tools + memory
â”‚   â”œâ”€â”€ evaluation.py    # Question generator & RAGAS scorer
â”‚   â”œâ”€â”€ rag_store.py     # Vector store wrapper
â”‚   â”œâ”€â”€ tools.py         # account / billing actions
â”‚   â”œâ”€â”€ initialize_db.py # SQLite for unhandled queries
â”‚   â””â”€â”€ Dockerfile
â”œâ”€â”€ frontend/
â”‚   â”œâ”€â”€ public/          # static HTML/CSS/JS
â”‚   â””â”€â”€ Dockerfile
â””â”€â”€ images/
    â”œâ”€â”€ anchortel_chatbot_arch_enhanced.png
 

---

## ğŸ› ï¸ Technologies

- FastAPI   Â·  LangChain / LangGraph 0.4.8   Â·  OpenAI GPTâ€‘4o
- FAISS / Chroma vector store   Â·  RAGAS metrics
- Docker   Â·  Google Cloud Run   Â·  Python 3.10

---

## âš™ï¸ Backend Setup

```bash
cd backend
python -m venv venv && source venv/bin/activate
pip install -r requirements.txt
cp .env.example .env  # add OPENAI_API_KEY
uvicorn main:app --reload --port 8080
```

### Cloud Run

```bash
make build   # docker build -t gcr.io/<project>/anchortel-backend .
make deploy  # gcloud run deploy â€¦
```

---

## ğŸ–¥ï¸ Frontend Setup

```bash
cd frontend/public
npx http-server . -p 8080
```

Dockerized deployment:

```bash
cd frontend && make build && make deploy
```

---

## ğŸ”Œ API Endpoints

| Endpoint              | Method      | Purpose                                   |
| --------------------- | ----------- | ----------------------------------------- |
| `/chat`               | POST        | Main chatbot interface                    |
| `/generate-questions` | POST        | Autoâ€‘create *n* reference Q&A rows        |
| `/evaluate-excel`     | POST (file) | Upload workbook â†’ returns scored workbook |
| `/test`               | GET         | Health check                              |

---

## ğŸ“Š Automatic Evaluation Workflow

1. **Generate** â€“ `POST /generate-questions?n=25` â†’ receive **questions.xlsx** with blank *Answer* column.
2. **Curate** â€“ SMEs tweak reference answers and questions directly in Excel.
3. **Evaluate** â€“ upload the sheet to `POST /evaluate-excel`.
4. **Metrics** â€“ backend computes faithfulness, contextâ€‘precision, contextâ€‘recall, answerâ€‘relevancy, answerâ€‘similarity via RAGAS.
5. **Download** â€“ get **evaluated.xlsx** ready for reporting.

---

## ğŸ“ UML Sequence (Mermaid)

```mermaid
sequenceDiagram
    autonumber

    %% PARTICIPANTS
    participant User
    participant FastAPI
    participant ChatSvc  as Chat_Service
    participant EvalSvc  as Evaluation_Service
    participant Agent
    participant RAG
    participant VectorDB
    participant OpenAI
    participant RAGAS
    participant Excel

    %% ---------- 1. CHAT ROUND-TRIP ----------
    User ->> FastAPI: POST /chat {query}
    FastAPI ->> ChatSvc: forward
    ChatSvc ->> Agent: handle_query()
    Agent ->> RAG: retrieve(query)
    RAG ->> VectorDB: similarity_search
    VectorDB -->> RAG: docs
    RAG -->> Agent: context
    Agent ->> OpenAI: completion(prompt+context)
    OpenAI -->> Agent: answer
    Agent -->> ChatSvc: {answer, sources}
    ChatSvc -->> FastAPI: response
    FastAPI -->> User: JSON

    %% ---------- 2. GENERATE TEST Q&A ----------
    User ->> FastAPI: POST /generate-questions
    FastAPI ->> EvalSvc: forward
    EvalSvc ->> OpenAI: generate n Q&A
    OpenAI -->> EvalSvc: list[Q,A]
    EvalSvc ->> Excel: create questions.xlsx
    EvalSvc -->> FastAPI: download link
    FastAPI -->> User: Excel URL

    %% ---------- 3. EVALUATE EXCEL ----------
    User ->> FastAPI: POST /evaluate-excel
    FastAPI ->> EvalSvc: file stream
    EvalSvc ->> OpenAI: LLM answers per Q
    OpenAI -->> EvalSvc: answers
    EvalSvc ->> RAGAS: compute metrics
    RAGAS ->> OpenAI: sub-eval calls
    OpenAI -->> RAGAS: scores
    RAGAS -->> EvalSvc: metrics table
    EvalSvc ->> Excel: append â†’ evaluated.xlsx
    EvalSvc -->> FastAPI: download link
    FastAPI -->> User: evaluated.xlsx

```

---

## ğŸ›¡ï¸ Security Notes

- Secrets in `.env` (use Secret Manager in prod)
- Basic Auth & CORS for demo; swap to OAuth2 for production
- Rateâ€‘limit evaluation endpoints to control token cost

---

## ğŸ—ºï¸ Roadmap

- CI/CD via GitHub Actions + Terraform
- Prometheus / Grafana latency & cost dashboards
- Outageâ€‘credit & planâ€‘change tools
- Bedrock Titan fineâ€‘tune for AnchorTel tone


    
